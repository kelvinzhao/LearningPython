{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVERVIEW\n",
    "\n",
    "![](https://si.wsj.net/public/resources/images/B3-DM067_RIGHTS_IM_20190319162958.jpg)\n",
    "\n",
    "Here I made an ULTIMATE Top 5% House Pricing Guide to making a great House Pricing model. \n",
    "This guide consists of many explanations and simple actions in order to efficiently process data and setup a model for submission. Data Visualization is used a lot in this notebook in order to understand the data clearly and perform necessary actions.\n",
    "\n",
    "I will constantly update this notebook if I find a more efficient way to doing something or if lots of support is shown for this notebook so please show your support and like this notebook in order to motivate me to updating this notebook more often. If you have questions or any tips please comment below üòÅ. VERSION LOGS are below.\n",
    "\n",
    "\n",
    "# VERSION LOGS:\n",
    "### - Version 1: \n",
    "- RELEASED\n",
    "\n",
    "<br>\n",
    "\n",
    "### - Version 2 [CURRENT]: \n",
    "- Added Data Science Workflow map for a general idea of the process\n",
    "- New subsection 'SalePrice Distribution' which visualizes SalePrice before and after log-transformation\n",
    "- We decide to log-transform SalePrice and inverse-transform it during modelling\n",
    "\n",
    "\n",
    "# TABLE OF CONTENTS:\n",
    "### [1) IMPORTING LIBRARIES](#1)\n",
    "### [2) READING DATA AND COMPREHENDING DATA](#2)\n",
    "### [3) DATA VISUALIZATION](#3)\n",
    "### [4) DATA PROCESSING](#4)\n",
    "### [5) FEATURE ENGINEERING](#5)\n",
    "### [6) MODELLING](#6)\n",
    "### [7) SUBMISSION](#7)\n",
    "\n",
    "# DATA SCIENCE WORKFLOW:\n",
    "![](https://miro.medium.com/max/2000/1*3FQbrDoP1w1oibNPj9YeDw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLEASE <font color='red'><b>U</b></font><font color='orange'><b>P</b></font><font color='yellow'><b>V</b></font><font color='green'><b>O</b></font><font color='blue'><b>T</b></font><font color='purple'><b>E</b></font>üëç if you found HELPFUL!  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "# 1) IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "# 2) READING DATA AND COMPREHENDING DATA\n",
    "In this section:\n",
    "- 2.1 Reading Data\n",
    "- 2.2 Understanding the Data\n",
    "- 2.3 Checking for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = pd.read_csv('../input/home-data-for-ml-course/train.csv',index_col='Id')\n",
    "test = pd.read_csv('../input/home-data-for-ml-course/test.csv',index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values\n",
    "missing = home.isnull().sum()\n",
    "missing = missing[missing>0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "# 3) DATA VISUALIZATION\n",
    "In this section:\n",
    "\n",
    "- 3.1 Viewing Columns\n",
    "\n",
    "- 3.2 Distribution of Data\n",
    "\n",
    "- 3.3 Univariate Analysis of Data\n",
    "\n",
    "- 3.4 Bivariate Analysis of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Viewing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = home.select_dtypes(exclude=['object']).drop(['SalePrice'], axis=1).copy()\n",
    "print(numerical_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = home.select_dtypes(include=['object']).copy()\n",
    "print(categorical_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Distribution of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,18))\n",
    "for i in range(len(numerical_features.columns)):\n",
    "    fig.add_subplot(9,4,i+1)\n",
    "    sns.distplot(numerical_features.iloc[:,i].dropna(), rug=True, hist=False, label='UW', kde_kws={'bw':0.1})\n",
    "    plt.xlabel(numerical_features.columns[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,18))\n",
    "for i in range(len(numerical_features.columns)):\n",
    "    fig.add_subplot(9,4,i+1)\n",
    "    sns.boxplot(y=numerical_features.iloc[:,i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,18))\n",
    "for i in range(len(numerical_features.columns)):\n",
    "    fig.add_subplot(9, 4, i+1)\n",
    "    sns.scatterplot(numerical_features.iloc[:, i],home['SalePrice'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "# 4) DATA PROCESSING\n",
    "In this section:\n",
    "- 4.1 Outliers\n",
    "- 4.2 Removing Certain Features\n",
    "- 4.3 Filling Numerical Missing Values\n",
    "- 4.4 Filling Categorical Missing Values\n",
    "- 4.5 Filling Missing Values in 'LotFrontage'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on Outliers:\n",
    "According to the plots above, these are the features which appear to have outliers:\n",
    "- LotFrontage\n",
    "- LotArea\n",
    "- MasVnrArea\n",
    "- BsmtFinSF1\n",
    "- TotalBsmtSF\n",
    "- GrLivArea\n",
    "- 1stFlrSF\n",
    "- EnclosedPorch\n",
    "- MiscVal\n",
    "- LowQualFinSF\n",
    "\n",
    "Let's take a closer look at these features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(nrows=5, ncols=2)\n",
    "figure.set_size_inches(16,28)\n",
    "_ = sns.regplot(home['LotFrontage'], home['SalePrice'], ax=ax1)\n",
    "_ = sns.regplot(home['LotArea'], home['SalePrice'], ax=ax2)\n",
    "_ = sns.regplot(home['MasVnrArea'], home['SalePrice'], ax=ax3)\n",
    "_ = sns.regplot(home['BsmtFinSF1'], home['SalePrice'], ax=ax4)\n",
    "_ = sns.regplot(home['TotalBsmtSF'], home['SalePrice'], ax=ax5)\n",
    "_ = sns.regplot(home['GrLivArea'], home['SalePrice'], ax=ax6)\n",
    "_ = sns.regplot(home['1stFlrSF'], home['SalePrice'], ax=ax7)\n",
    "_ = sns.regplot(home['EnclosedPorch'], home['SalePrice'], ax=ax8)\n",
    "_ = sns.regplot(home['MiscVal'], home['SalePrice'], ax=ax9)\n",
    "_ = sns.regplot(home['LowQualFinSF'], home['SalePrice'], ax=ax10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these regplots we have confirmed there are outliers, so we decide to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = home.drop(home[home['LotFrontage']>200].index)\n",
    "home = home.drop(home[home['LotArea']>100000].index)\n",
    "home = home.drop(home[home['MasVnrArea']>1200].index)\n",
    "home = home.drop(home[home['BsmtFinSF1']>4000].index)\n",
    "home = home.drop(home[home['TotalBsmtSF']>4000].index)\n",
    "home = home.drop(home[(home['GrLivArea']>4000) & (home['SalePrice']<300000)].index)\n",
    "home = home.drop(home[home['1stFlrSF']>4000].index)\n",
    "home = home.drop(home[home['EnclosedPorch']>500].index)\n",
    "home = home.drop(home[home['MiscVal']>5000].index)\n",
    "home = home.drop(home[(home['LowQualFinSF']>600) & (home['SalePrice']>400000)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Removing Certain Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the highly-correlated (correlations higher than 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correlation = home.select_dtypes(exclude='object').corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.title('High Correlation')\n",
    "sns.heatmap(num_correlation > 0.8, annot=True, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly-Correlated Features:\n",
    "- YearBuilt vs GarageYrBlt\n",
    "- 1stFlrSF vs TotalBsmtSF\n",
    "- GrLivArea vs TotRmsAbvGrd\n",
    "- GarageCars vs GarageArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = num_correlation.corr()\n",
    "print(corr['SalePrice'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop column with a lower correlation to SalePrice of the pair\n",
    "\n",
    "(Ex: GarageCars(0.88) & GarageArea(0.876))\n",
    "\n",
    "**DROP GarageArea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.drop(columns=['GarageArea','TotRmsAbvGrd','GarageYrBlt','1stFlrSF'],axis=1,inplace=True) \n",
    "test.drop(columns=['GarageArea','TotRmsAbvGrd','GarageYrBlt','1stFlrSF'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have useless features so we also decide to drop the features below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useless Columns...\n",
    "home=home.drop(columns=['Street','Utilities','Condition2','RoofMatl','Heating']) \n",
    "test=test.drop(columns=['Street','Utilities','Condition2','RoofMatl','Heating']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see which features have the most missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.isnull().mean().sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see features 'Alley', 'MiscFeature' and 'PoolQC' are missing over 90% of their values. So we decide to remove them.\n",
    "'PoolArea' is pretty much a useless column because 99.6% of 'PoolQC' is missing so we also drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.drop(columns=['Alley','MiscFeature','PoolQC','PoolArea'], axis=1, inplace=True)\n",
    "test.drop(columns=['Alley','MiscFeature','PoolQC','PoolArea'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().mean().sort_values(ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data doesn't have any features that have over 90% of missing values. So we don't drop any features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Filling Numerical Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Home and Test data missing value percentage\n",
    "null = pd.DataFrame(data={'Home Null Percentage': home.isnull().sum()[home.isnull().sum() > 0], 'Test Null Percentage': test.isnull().sum()[test.isnull().sum() > 0]})\n",
    "null = (null/len(home)) * 100\n",
    "\n",
    "null.index.name='Feature'\n",
    "null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.isnull().sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_num_features = home.select_dtypes(exclude='object').isnull().mean()\n",
    "test_num_features = test.select_dtypes(exclude='object').isnull().mean()\n",
    "\n",
    "num_null_features = pd.DataFrame(data={'Missing Num Home Percentage: ': home_num_features[home_num_features>0], 'Missing Num Test Percentage: ': test_num_features[test_num_features>0]})\n",
    "num_null_features.index.name = 'Numerical Features'\n",
    "num_null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [home, test]:\n",
    "    for col in ('GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', \n",
    "                'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotalBsmtSF',\n",
    "                'Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal', 'MoSold', 'YrSold',\n",
    "                'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea'):\n",
    "                    df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=sns.regplot(home['LotFrontage'],home['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_num_features = home.select_dtypes(exclude='object').isnull().mean()\n",
    "test_num_features = test.select_dtypes(exclude='object').isnull().mean()\n",
    "\n",
    "num_null_features = pd.DataFrame(data={'Missing Num Home Percentage: ': home_num_features[home_num_features>0], 'Missing Num Test Percentage: ': test_num_features[test_num_features>0]})\n",
    "num_null_features.index.name = 'Numerical Features'\n",
    "num_null_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will deal with 'LotFrontage' later because it is an important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Filling Categorical Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = home.select_dtypes(include='object').columns\n",
    "print(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_cat_features = home.select_dtypes(include='object').isnull().mean()\n",
    "test_cat_features = test.select_dtypes(include='object').isnull().mean()\n",
    "\n",
    "cat_null_features = pd.DataFrame(data={'Missing Cat Home Percentage: ': home_cat_features[home_cat_features>0], 'Missing Cat Test Percentage: ': test_cat_features[test_cat_features>0]})\n",
    "cat_null_features.index.name = 'Categorical Features'\n",
    "cat_null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = home.select_dtypes(include='object').columns\n",
    "\n",
    "columns = len(cat_col)/4+1\n",
    "\n",
    "fg, ax = plt.subplots(figsize=(20, 30))\n",
    "\n",
    "for i, col in enumerate(cat_col):\n",
    "    fg.add_subplot(columns, 4, i+1)\n",
    "    sns.countplot(home[col])\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = home['KitchenQual']\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "sns.boxplot(y=home.SalePrice, x=var)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,8))\n",
    "sns.boxplot(y=home.SalePrice, x=home.Neighborhood)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count of categories within Neighborhood attribute\n",
    "fig = plt.figure(figsize=(12.5,4))\n",
    "sns.countplot(x='Neighborhood', data=home)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [home, test]:\n",
    "    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "                  'BsmtFinType2', 'Neighborhood', 'BldgType', 'HouseStyle', 'MasVnrType', 'FireplaceQu', 'Fence'):\n",
    "        df[col] = df[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [home, test]:\n",
    "    for col in ('LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'RoofStyle',\n",
    "                  'Electrical', 'Functional', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'ExterQual', 'ExterCond',\n",
    "                  'Foundation', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition'):\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_cat_features = home.select_dtypes(include='object').isnull().mean()\n",
    "test_cat_features = test.select_dtypes(include='object').isnull().mean()\n",
    "\n",
    "cat_null_features = pd.DataFrame(data={'Missing Cat Home Percentage: ': home_cat_features[home_cat_features>0], 'Missing Cat Test Percentage: ': test_cat_features[test_cat_features>0]})\n",
    "cat_null_features.index.name = 'Categorical Features'\n",
    "cat_null_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Filling Missing Values in 'LotFrontage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=sns.regplot(home['LotFrontage'],home['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LotFrontage is correlated to Neighborhood, so we fill in the median based off of Neighborhood feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['LotFrontage'] = home.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))\n",
    "test['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.corr()['SalePrice'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining missing values we will impute them with 'SimpleImputer()' when modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "# 5) FEATURE ENGINEERING\n",
    "In this section:\n",
    "- 5.1 Create 'TotalSF' feature\n",
    "- 5.2 Create 'TotalBath' feature\n",
    "- 5.3 Create 'YrBuiltAndRemod' feature\n",
    "- 5.4 Create 'PorchSF' feature\n",
    "- 5.5 Creating extra features and changing types\n",
    "- 5.6 SalePrice Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(home.select_dtypes(exclude='object').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create 'TotalSF' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n",
    "figure.set_size_inches(20,10)\n",
    "_ = sns.regplot(home['TotalBsmtSF'], home['SalePrice'], ax=ax1)\n",
    "_ = sns.regplot(home['2ndFlrSF'], home['SalePrice'], ax=ax2)\n",
    "_ = sns.regplot(home['TotalBsmtSF'] + home['2ndFlrSF'], home['SalePrice'], ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['TotalSF']=home['TotalBsmtSF']  + home['2ndFlrSF']\n",
    "test['TotalSF']=test['TotalBsmtSF']  + test['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create 'TotalBath' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "figure.set_size_inches(14,10)\n",
    "_ = sns.barplot(home['BsmtFullBath'], home['SalePrice'], ax=ax1)\n",
    "_ = sns.barplot(home['FullBath'], home['SalePrice'], ax=ax2)\n",
    "_ = sns.barplot(home['BsmtHalfBath'], home['SalePrice'], ax=ax3)\n",
    "_ = sns.barplot(home['BsmtFullBath'] + home['FullBath'] + home['BsmtHalfBath'] + home['HalfBath'], home['SalePrice'], ax=ax4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['TotalBath']=home['BsmtFullBath'] + home['FullBath'] + (0.5*home['BsmtHalfBath']) + (0.5*home['HalfBath'])\n",
    "test['TotalBath']=test['BsmtFullBath'] + test['FullBath'] + test['BsmtHalfBath'] + test['HalfBath']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Create 'YrBuiltAndRemod' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n",
    "figure.set_size_inches(18,8)\n",
    "_ = sns.regplot(home['YearBuilt'], home['SalePrice'], ax=ax1)\n",
    "_ = sns.regplot(home['YearRemodAdd'], home['SalePrice'], ax=ax2)\n",
    "_ = sns.regplot((home['YearBuilt']+home['YearRemodAdd'])/2, home['SalePrice'], ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['YrBltAndRemod']=home['YearBuilt']+(home['YearRemodAdd']/2)\n",
    "test['YrBltAndRemod']=test['YearBuilt']+(test['YearRemodAdd']/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Create 'PorchSF' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3)\n",
    "figure.set_size_inches(20,10)\n",
    "_ = sns.regplot(home['OpenPorchSF'], home['SalePrice'], ax=ax1)\n",
    "_ = sns.regplot(home['3SsnPorch'], home['SalePrice'], ax=ax2)\n",
    "_ = sns.regplot(home['EnclosedPorch'], home['SalePrice'], ax=ax3)\n",
    "_ = sns.regplot(home['ScreenPorch'], home['SalePrice'], ax=ax4)\n",
    "_ = sns.regplot(home['WoodDeckSF'], home['SalePrice'], ax=ax5)\n",
    "_ = sns.regplot((home['OpenPorchSF']+home['3SsnPorch']+home['EnclosedPorch']+home['ScreenPorch']+home['WoodDeckSF']), home['SalePrice'], ax=ax6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['Porch_SF'] = (home['OpenPorchSF'] + home['3SsnPorch'] + home['EnclosedPorch'] + home['ScreenPorch'] + home['WoodDeckSF'])\n",
    "test['Porch_SF'] = (test['OpenPorchSF'] + test['3SsnPorch'] + test['EnclosedPorch'] + test['ScreenPorch'] + test['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Creating extra features and changing types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create extra features in order to categorize data with and without a feature\n",
    "\n",
    "For example:\n",
    "- 'HasPool' is 1 if you have pool and 0 if you don't have a pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['Has2ndfloor'] = home['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "home['HasBsmt'] = home['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "home['HasFirePlace'] = home['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "home['Has2ndFlr']=home['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "home['HasBsmt']=home['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "test['Has2ndfloor'] = test['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "test['HasBsmt'] = test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "test['HasFirePlace'] = test['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "test['Has2ndFlr']=test['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "test['HasBsmt']=test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features are the wrong type so we convert them to the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home['MSSubClass'] = home['MSSubClass'].apply(str)\n",
    "home['MoSold']=home['MoSold'].astype(str)\n",
    "home['YrSold']=home['YrSold'].astype(str)\n",
    "home['LotArea'] = home['LotArea'].astype(np.int64)\n",
    "\n",
    "test['MSSubClass'] = test['MSSubClass'].apply(str)\n",
    "test['MoSold']=test['MoSold'].astype(str)\n",
    "test['YrSold']=test['YrSold'].astype(str)\n",
    "test['LotArea'] = test['LotArea'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 SalePrice Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,11))\n",
    "\n",
    "print (\"Skew of SalePrice:\", home.SalePrice.skew())\n",
    "plt.hist(home.SalePrice, normed=1, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph shows that SalePrice is skewed to the right and must be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,11))\n",
    "\n",
    "print (\"Skew of Log-Transformed SalePrice:\", np.log1p(home.SalePrice).skew())\n",
    "plt.hist(np.log1p(home.SalePrice), color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the skew improved from approximately 1.88 to approximately 0.12 so we will log-transform SalePrice in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "# 6) MODELLING\n",
    "In this section:\n",
    "\n",
    "- 6.1 Dealing with Data for Modelling\n",
    "- 6.2 Finding the Best Model\n",
    "- 6.3 Setting up Final Model for Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Dealing with Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = home.drop(['SalePrice'], axis=1)\n",
    "y = np.log1p(home['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split X and y into train and valid data for model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select every numerical column from X and the categorical columns with unique values under 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [cname for cname in X.columns if\n",
    "                    X[cname].nunique() <= 30 and\n",
    "                    X[cname].dtype == \"object\"] \n",
    "                \n",
    "\n",
    "\n",
    "numerical_cols = [cname for cname in X.columns if\n",
    "                 X[cname].dtype in ['int64','float64']]\n",
    "\n",
    "\n",
    "my_cols = numerical_cols + categorical_cols\n",
    "\n",
    "X_train = X_train[my_cols].copy()\n",
    "X_valid = X_valid[my_cols].copy()\n",
    "X_test = test[my_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a 'num_transformer' and a 'cat_transformer' for imputing and hot-encoding numerical and categorical values. We then store these transformers into a preprocessor column transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(steps=[\n",
    "    ('num_imputer', SimpleImputer(strategy='constant'))\n",
    "    ])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numerical_cols),       \n",
    "        ('cat',cat_transformer,categorical_cols),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Finding the Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test three models: 'XGBoost', 'Lasso', and 'Gradient' and see which one performs the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversing log-transform on y\n",
    "def inv_y(transformed_y):\n",
    "    return np.exp(transformed_y)\n",
    "\n",
    "\n",
    "\n",
    "scores=[]\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "model_names = ['XGBoost','Lasso','Gradient']\n",
    "models =[XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                     max_depth=3, min_child_weight=0,\n",
    "                     gamma=0, subsample=0.7,\n",
    "                     colsample_bytree=0.7,\n",
    "                     objective='reg:squarederror', nthread=-1,\n",
    "                     scale_pos_weight=1, seed=27,\n",
    "                     reg_alpha=0.00006), \n",
    "         LassoCV(max_iter=1e7,  random_state=14, cv=n_folds), \n",
    "         GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=5)]\n",
    "\n",
    "for model in models:\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)])\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_valid)\n",
    "    score = mean_absolute_error(inv_y(y_valid), inv_y(preds))\n",
    "    scores.append(score)\n",
    "new_models_data_frame = pd.DataFrame({'Score': scores}, index=model_names)\n",
    "new_models_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see XGBoost performed the best so we will be using this for our final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Setting up Final Model for Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the best model XGBoost and combine it with preprocessor which imputes and hot-encodes missing data. We then train and predict the combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                     max_depth=3, min_child_weight=0,\n",
    "                     gamma=0, subsample=0.7,\n",
    "                     colsample_bytree=0.7,\n",
    "                     objective='reg:squarederror', nthread=-1,\n",
    "                     scale_pos_weight=1, seed=27,\n",
    "                     reg_alpha=0.00006)\n",
    "\n",
    "final_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)])\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "final_predictions = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "# 7) SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': inv_y(final_predictions)})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
